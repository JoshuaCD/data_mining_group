{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California Housing Data Regression\n",
    "\n",
    "#### Utilize numerous regression techniques, with Median House Value as the target variable and evaluate the performance of each as well as results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing # Brings in Dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import plotly.express as px\n",
    "#import geopandas\n",
    "from pandas_profiling import ProfileReport\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "import plotly.graph_objects as go\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, Lasso\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor, plot_importance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set plotting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = [12, 8]\n",
    "sns.set_style('darkgrid')\n",
    "sns.set(font_scale=1.2)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Classes/Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(method, x_dat, y_dat, regression_type, **params):\n",
    "    \n",
    "    #fit model\n",
    "    mod = method(**params)\n",
    "    mod.fit(x_dat, y_dat)\n",
    "    y_pred = mod.predict(x_dat)\n",
    "    \n",
    "    regression_results(y_dat, y_pred)\n",
    "    \n",
    "    if regression_type == 'Tree':\n",
    "        print('Feature Importance Plot')\n",
    "        sns.barplot(y=x_dat.columns, x=mod.feature_importances_)\n",
    "        plt.xlabel('Mean Decrease Gini')\n",
    "        plt.show()\n",
    "    \n",
    "    if regression_type == 'Linear':\n",
    "        coef_results(x_dat, mod)\n",
    "        \n",
    "    print('Predicted Vs. Actual By Location')\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24,12))\n",
    "    sns.scatterplot(x=x_dat.Longitude, y=x_dat.Latitude, hue=y_dat, ax=ax1, palette = 'viridis', hue_norm = (y_dat.min(), y_dat.max()))\n",
    "    sns.scatterplot(x=x_dat.Longitude, y=x_dat.Latitude, hue=y_pred, ax=ax2, palette= 'viridis', hue_norm = (y_dat.min(), y_dat.max()))\n",
    "    ax1.set_title('Actual Housing values')\n",
    "    ax2.set_title('Predicted Housing Values')\n",
    "    plt.show()\n",
    "    \n",
    "    print('Predicted Vs. Actual Values')\n",
    "    plt.figure(figsize=(12,12))\n",
    "    sns.scatterplot(x=y_dat, y=y_pred)\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_results(y_true, y_pred):\n",
    "    print(color.UNDERLINE+'EVALUATION METRICS'+color.END)\n",
    "    # Regression metrics\n",
    "    mean_absolute_error=metrics.mean_absolute_error(y_true, y_pred) \n",
    "    mse=metrics.mean_squared_error(y_true, y_pred) \n",
    "    median_absolute_error=metrics.median_absolute_error(y_true, y_pred)\n",
    "    r2=metrics.r2_score(y_true, y_pred)\n",
    " \n",
    "    print(color.BOLD + 'R2:  ' + color.END, round(r2,5))\n",
    "    print(color.BOLD + 'MAE: ' + color.END, round(mean_absolute_error,5))\n",
    "    print(color.BOLD + 'MSE: ' + color.END, round(mse,5))\n",
    "    print(color.BOLD + 'RMSE:' + color.END, round(np.sqrt(mse),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coef_results(x_train,model):\n",
    "    print(color.UNDERLINE+'COEFFICIENTS'+color.END)\n",
    "    print(color.BOLD +\"Intercept:\" + color.END,\n",
    "          round(model.intercept_,4))\n",
    "    for i in range(model.n_features_in_):\n",
    "        print(color.BOLD + str(x.columns[i])+':'+ color.END,\n",
    "              round(model.coef_[i],6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset, Explore and Display Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "housing_df = pd.DataFrame(data= np.c_[housing['data'], housing['target']],\n",
    "                     columns= housing['feature_names'] + ['MedHouseVal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(housing_df)\n",
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Linear Regression With Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols(data=housing_df, formula='MedHouseVal ~ MedInc + AveRooms + Latitude + HouseAge + AveBedrms + Longitude + Population + AveOccup')\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geographic plot of  Median House Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a spatial map of the housing data with the Median House Value \n",
    "# binned and represented by size of its point and color\n",
    "\n",
    "fig_dims = (6, 7) # Using Dims to try to simulate Cali Shape\n",
    "fig, ax = plt.subplots(figsize=fig_dims)  \n",
    "sns.scatterplot(data=housing_df, x=\"Longitude\", y=\"Latitude\",\n",
    "                size=\"MedHouseVal\", hue=\"MedHouseVal\",\n",
    "                palette=\"viridis\", alpha=0.5)\n",
    "\n",
    "plt.legend(title=\"MedHouseVal\", bbox_to_anchor=(1.05, 0.95),\n",
    "           loc=\"upper left\")\n",
    "_ = plt.title(\"Median house value by spatial location\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairplot of predictive attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating pairplot of predictive attributes and Median House Value (target)\n",
    "# This is ignoring Latitude and Longitude\n",
    "\n",
    "housing_df_noGeo = housing_df.drop(columns=['Latitude','Longitude'])\n",
    "housing_df_noGeo[\"target\"] = pd.qcut(housing_df_noGeo[\"MedHouseVal\"],\n",
    "                                     6, retbins=False)\n",
    "housing_df_noGeo[\"target\"] = housing_df_noGeo[\"target\"].apply(lambda x: x.mid)\n",
    "\n",
    "_ = sns.pairplot(data=housing_df_noGeo, hue=\"target\", palette=\"viridis\")\n",
    "\n",
    "### Note: can someone find a better way to display this? feels a bit hard to read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables by County Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could not get below to run for me so just commented out for time being"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a geopandas dataframe with the latitude/longitude values\n",
    "# housing_gdf = geopandas.GeoDataFrame(\n",
    "#     housing_df, geometry=geopandas.points_from_xy(housing_df.Longitude, housing_df.Latitude))\n",
    "\n",
    "# print(housing_gdf.head())\n",
    "\n",
    "# # County information from the US 2018 census\n",
    "# counties = geopandas.read_file('CA_Counties_TIGER2016.shp')\n",
    "# print(counties.head())\n",
    "\n",
    "\n",
    "# # Below are all some iterations of what I've tried; I'm getting confused trying to merge the \n",
    "# # county lines and the latitude/longitude values from the dataset; I'm having a hard time\n",
    "# # figuring out how to make them comparable \n",
    "\n",
    "# ax = counties.boundary.plot(color='black', figsize=(18, 12))\n",
    "\n",
    "# ax.plot()\n",
    "\n",
    "# fig = px.scatter_geo(housing_gdf)\n",
    "\n",
    "# fig.show()\n",
    "\n",
    "# housing_gdf.plot(ax=ax, color='red')\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "#     all_counties = json.load(response)\n",
    "\n",
    "# fig = px.choropleth(housing_gdf, geojson=counties, locations='geometry', color='target',\n",
    "#                            range_color=(0, 12),\n",
    "#                            scope=\"usa\"\n",
    "#                           )\n",
    "# fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "# fig.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinary Least Squares Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLS_Regression(df):\n",
    "    Y = df['MedHouseVal']\n",
    "    for col in df.iloc[:,0:6]:\n",
    "        print(color.BOLD + col + color.END)\n",
    "        X = df[col]\n",
    "        X = sm.add_constant(X)\n",
    "        model = sm.OLS(Y,X)\n",
    "        results = model.fit()\n",
    "        print(color.BOLD +\"Results: \" + color.END + str(results.params))\n",
    "        print(color.BOLD +\"T-values: \"+ color.END + str(results.tvalues))\n",
    "        print(color.BOLD +\"T-Test: \" + color.END + str(results.t_test([1, 0])))\n",
    "        print('')\n",
    "    \n",
    "    \n",
    "OLS_Regression(housing_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize the data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = housing_df\n",
    "scaled_array = StandardScaler().fit_transform(x) # This is an array of the standardized values of the original columns\n",
    "housing_standardized = pd.DataFrame(data= np.c_[scaled_array],\\\n",
    "                                    columns = ('MedInc', 'HouseAge', 'AveRooms', 'AveBedrms','Population',\\\n",
    "                                               'AveOccup','Latitude','Longitude', 'MedHouseVal'))\n",
    "# View standardized data frame\n",
    "housing_standardized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target into x and y \n",
    "## for both unchanged and standardized Dataframes\n",
    "\n",
    "x_housing = housing_df.drop(columns='MedHouseVal')\n",
    "y_housing = housing_df['MedHouseVal']\n",
    "x_housing_scaled = housing_standardized.drop(columns='MedHouseVal')\n",
    "y_housing_scaled = housing_standardized['MedHouseVal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression(LinearRegression, x_housing, y_housing, 'Linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardized Data\n",
    "\n",
    "# Define the multiple linear regression model\n",
    "linear_regress_scaled = LinearRegression()\n",
    "\n",
    "# Fit the multiple linear regression model\n",
    "linear_regress_scaled.fit(x_housing_scaled,y_housing_scaled)\n",
    "\n",
    "# Predict y hat with the data\n",
    "y_pred_mlr_scaled = linear_regress_scaled.predict(x_housing_scaled)\n",
    "\n",
    "# Return R-squared, MSE, and RMSE scores\n",
    "coef_results(x_housing,linear_regress_scaled)\n",
    "regression_results(y_housing_scaled,y_pred_mlr_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression(LinearRegression, x_housing_scaled, y_housing_scaled, 'Linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RidgeCV Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression(RidgeCV, x_housing, y_housing, 'Linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression(RidgeCV, x_housing_scaled, y_housing_scaled, 'Linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression(Lasso, x_housing, y_housing, 'Linear', alpha=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression(Lasso, x_housing_scaled, y_housing_scaled, 'Linear', alpha=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression(RandomForestRegressor, x_housing, y_housing, 'Tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression(XGBRegressor, x_housing, y_housing, 'Tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XGBoost model performs well, although it is noticable worse than the Random forest. It performs much better if it is given more estimators and depth, but this algorithm can also be prone to overfit and the feature importance starts looking odd if the number of estimators is increased too much, so I decided to stick with the default parameters for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Before tuning hyper parameters, the best performing models are Linear Regression and CV Ridge Regression. The feature MedInc seems to have the largest impact on the set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree based models perform much better than the linear models. The linear models tend to miss the high value areas and assign less importance to latitude and longitude, where the more sophisticated decision tree based models do a better job of correctly classifying the high value areas and they seem to be assigning more weight to latitude and longitude in their decisions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
