{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California Housing Data Regression\n",
    "\n",
    "#### Utilize numerous regression techniques, with Median House Value as the target variable and evaluate the performance of each as well as results.\n",
    "\n",
    "#### Note techniques used include:\n",
    "1. Linear Regression\n",
    "2. RidgeCV\n",
    "3. Lasso\n",
    "4. Random Forest\n",
    "5. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing # Brings in Dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import plotly.express as px\n",
    "#import geopandas\n",
    "from pandas_profiling import ProfileReport\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "import plotly.graph_objects as go\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, Lasso\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor, plot_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set plotting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = [12, 8]\n",
    "sns.set_style('darkgrid')\n",
    "sns.set(font_scale=1.2)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Classes/Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(method, x_dat, y_dat, regression_type, **params):\n",
    "    \n",
    "    #fit model\n",
    "    mod = method(**params)\n",
    "    mod.fit(x_dat, y_dat)\n",
    "    y_pred = mod.predict(x_dat)\n",
    "    \n",
    "    regression_results(y_dat, y_pred)\n",
    "    \n",
    "    if regression_type == 'Tree':\n",
    "        print('Feature Importance Plot')\n",
    "        sns.barplot(y=x_dat.columns, x=mod.feature_importances_)\n",
    "        plt.xlabel('Mean Decrease Gini')\n",
    "        plt.show()\n",
    "    \n",
    "    if regression_type == 'Linear':\n",
    "        coef_results(x_dat, mod)\n",
    "        \n",
    "    print('Predicted Vs. Actual By Location')\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24,12))\n",
    "    sns.scatterplot(x=x_dat.Longitude, y=x_dat.Latitude, hue=y_dat, ax=ax1, palette = 'viridis',\\\n",
    "                    hue_norm = (y_dat.min(), y_dat.max()))\n",
    "    sns.scatterplot(x=x_dat.Longitude, y=x_dat.Latitude, hue=y_pred, ax=ax2, palette= 'viridis',\\\n",
    "                    hue_norm = (y_dat.min(), y_dat.max()))\n",
    "    ax1.set_title('Actual Housing values')\n",
    "    ax2.set_title('Predicted Housing Values')\n",
    "    plt.show()\n",
    "    \n",
    "    print('Predicted Vs. Actual Values')\n",
    "    plt.figure(figsize=(12,12))\n",
    "    sns.scatterplot(x=y_dat, y=y_pred)\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_results(y_true, y_pred):\n",
    "    print(color.UNDERLINE+'EVALUATION METRICS'+color.END)\n",
    "    # Regression metrics\n",
    "    mean_absolute_error=metrics.mean_absolute_error(y_true, y_pred) \n",
    "    mse=metrics.mean_squared_error(y_true, y_pred) \n",
    "    median_absolute_error=metrics.median_absolute_error(y_true, y_pred)\n",
    "    r2=metrics.r2_score(y_true, y_pred)\n",
    " \n",
    "    print(color.BOLD + 'R2:  ' + color.END, round(r2,5))\n",
    "    print(color.BOLD + 'MAE: ' + color.END, round(mean_absolute_error,5))\n",
    "    print(color.BOLD + 'MSE: ' + color.END, round(mse,5))\n",
    "    print(color.BOLD + 'RMSE:' + color.END, round(np.sqrt(mse),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coef_results(x_train,model):\n",
    "    print(color.UNDERLINE+'COEFFICIENTS'+color.END)\n",
    "    print(color.BOLD +\"Intercept:\" + color.END,\n",
    "          round(model.intercept_,4))\n",
    "    for i in range(model.n_features_in_):\n",
    "        print(color.BOLD + str(x.columns[i])+':'+ color.END,\n",
    "              round(model.coef_[i],6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset, Explore and Display Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "housing_df = pd.DataFrame(data= np.c_[housing['data'], housing['target']],\n",
    "                     columns= housing['feature_names'] + ['MedHouseVal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(housing_df)\n",
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairplot of predictive attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pandas qcut with q=4 divides the median house values into 4 categories, consistent with the quantiles\n",
    "# seen in the Describe() function above.  This will make using the median house value as the hue in pairplots easier.\n",
    "housing_df_pairplots = housing_df.copy(deep=True)\n",
    "\n",
    "housing_df_pairplots['MedHouseValQuartiles'] = pd.qcut(housing_df_pairplots['MedHouseVal'], q=4)\n",
    "\n",
    "housing_df_pairplots['MedHouseValQuartiles'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating pairplot of predictive attributes and Median House Value (target) using q.cut into quantiles\n",
    "\n",
    "bin_labels = ['min-25%', '25%-50%', '50%-75%', '75%-max']\n",
    "\n",
    "housing_df_pairplots[\"MedHouseValQuartiles\"] = pd.qcut(housing_df_pairplots[\"MedHouseVal\"], q=4, labels=bin_labels)\n",
    "\n",
    "# Using corner = True will only display the lower triangle. Use for easier viewing as the top triangle is the same info\n",
    "sns.pairplot(housing_df_pairplots, hue='MedHouseValQuartiles', palette=\"viridis\", corner=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize the data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = housing_df\n",
    "scaled_array = StandardScaler().fit_transform(x) # This is an array of the standardized values of the original columns\n",
    "housing_standardized = pd.DataFrame(data= np.c_[scaled_array],\\\n",
    "                                    columns = ('MedInc', 'HouseAge', 'AveRooms', 'AveBedrms','Population',\\\n",
    "                                               'AveOccup','Latitude','Longitude', 'MedHouseVal'))\n",
    "# View standardized data frame\n",
    "housing_standardized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target into x and y \n",
    "## for both unchanged and standardized Dataframes\n",
    "\n",
    "x_housing = housing_df.drop(columns='MedHouseVal')\n",
    "y_housing = housing_df['MedHouseVal']\n",
    "x_housing_scaled = housing_standardized.drop(columns='MedHouseVal')\n",
    "y_housing_scaled = housing_standardized['MedHouseVal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression(LinearRegression, x_housing, y_housing, 'Linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression(LinearRegression, x_housing_scaled, y_housing_scaled, 'Linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RidgeCV Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression(RidgeCV, x_housing, y_housing, 'Linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression(RidgeCV, x_housing_scaled, y_housing_scaled, 'Linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression(Lasso, x_housing, y_housing, 'Linear', alpha=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression(Lasso, x_housing_scaled, y_housing_scaled, 'Linear', alpha=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression(RandomForestRegressor, x_housing, y_housing, 'Tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression(XGBRegressor, x_housing, y_housing, 'Tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XGBoost model performs well, although it is noticable worse than the Random forest. It performs much better if it is given more estimators and depth, but this algorithm can also be prone to overfit and the feature importance starts looking odd if the number of estimators is increased too much, so I decided to stick with the default parameters for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Before tuning hyper parameters, the best performing models are Linear Regression and CV Ridge Regression. The feature MedInc seems to have the largest impact on the set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree based models perform much better than the linear models. The linear models tend to miss the high value areas and assign less importance to latitude and longitude, where the more sophisticated decision tree based models do a better job of correctly classifying the high value areas and they seem to be assigning more weight to latitude and longitude in their decisions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
